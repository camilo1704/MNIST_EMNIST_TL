{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST con EMNIST features\n",
    "\n",
    "En este notebook se entrena una red que utiliza los features aprendidos a partir de la clasificaci√≥n de EMNIST para clasificar datos de la base de datos de MNIST. Para ello se hace lo mismo de siempre, se divide la red en features layers y classification layes, se copian los pesos de la parte de feature layers y se entrenan los pesos de la parte de clasificacion utilizando la nueva base de datos. Se obtuvo con 15 epocas un accuracy de 99.25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuchuflito/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "import imageio\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from skimage import transform,io\n",
    "from resizeimage import resizeimage\n",
    "import scipy.io as sio\n",
    "import scipy.misc\n",
    "#import ImageOps\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.transform import rescale, resize as rs, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 1,201,946\n",
      "Trainable params: 1,201,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=load_model('modelo_EMNIST_ok.h5')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leido de csv con pd\n",
    "#Y_train = df_XY_train['label'].values\n",
    "#X_train = df_XY_train.drop('label', axis=1).values\n",
    "#X_test  = df_X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1) #tensorflow channels_last\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1).astype('float32')/255\n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "X_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32')/255\n",
    "Y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape = (28,28,1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "]\n",
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel=Sequential(feature_layers+classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "weights= [layer.get_weights() for layer in model.layers]\n",
    "for i in np.arange(0,len(feature_layers),1):\n",
    "        newmodel.layers[i].set_weights(weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.1377 - acc: 0.9581 - val_loss: 0.0351 - val_acc: 0.9882\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 60s 996us/step - loss: 0.0592 - acc: 0.9822 - val_loss: 0.0279 - val_acc: 0.9908\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 60s 998us/step - loss: 0.0458 - acc: 0.9863 - val_loss: 0.0278 - val_acc: 0.9907\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 58s 964us/step - loss: 0.0375 - acc: 0.9888 - val_loss: 0.0279 - val_acc: 0.9909\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 55s 909us/step - loss: 0.0330 - acc: 0.9894 - val_loss: 0.0254 - val_acc: 0.9919\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 54s 905us/step - loss: 0.0282 - acc: 0.9913 - val_loss: 0.0264 - val_acc: 0.9915\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 55s 912us/step - loss: 0.0251 - acc: 0.9922 - val_loss: 0.0261 - val_acc: 0.9922\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 55s 918us/step - loss: 0.0234 - acc: 0.9927 - val_loss: 0.0258 - val_acc: 0.9923\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 55s 925us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0234 - val_acc: 0.9924\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 56s 928us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0280 - val_acc: 0.9922\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 55s 923us/step - loss: 0.0179 - acc: 0.9946 - val_loss: 0.0281 - val_acc: 0.9926\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 56s 929us/step - loss: 0.0189 - acc: 0.9945 - val_loss: 0.0300 - val_acc: 0.9915\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 55s 925us/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.0273 - val_acc: 0.9926\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 56s 927us/step - loss: 0.0149 - acc: 0.9958 - val_loss: 0.0262 - val_acc: 0.9926\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 56s 928us/step - loss: 0.0146 - acc: 0.9957 - val_loss: 0.0267 - val_acc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ef26ae748>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "newmodel.fit(X_train, Y_train, batch_size=128, epochs=15, verbose=1,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel.save('MNIST_with_EMNIST_features.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in model.layers:\n",
    "\tlayers.trainable=False\n",
    "model.layers[-1].trainable=True\n",
    "model.layers[-3].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.1312 - acc: 0.9607 - val_loss: 0.0506 - val_acc: 0.9838\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0726 - acc: 0.9784 - val_loss: 0.0411 - val_acc: 0.9866\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0566 - acc: 0.9832 - val_loss: 0.0307 - val_acc: 0.9892\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0482 - acc: 0.9854 - val_loss: 0.0301 - val_acc: 0.9903\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0421 - acc: 0.9877 - val_loss: 0.0267 - val_acc: 0.9908\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0368 - acc: 0.9888 - val_loss: 0.0268 - val_acc: 0.9906\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0346 - acc: 0.9893 - val_loss: 0.0294 - val_acc: 0.9909\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0309 - acc: 0.9907 - val_loss: 0.0240 - val_acc: 0.9922\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0276 - acc: 0.9915 - val_loss: 0.0252 - val_acc: 0.9918\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0238 - val_acc: 0.9922\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0253 - acc: 0.9920 - val_loss: 0.0229 - val_acc: 0.9928\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0221 - acc: 0.9930 - val_loss: 0.0242 - val_acc: 0.9919\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0253 - val_acc: 0.9916\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0216 - acc: 0.9932 - val_loss: 0.0255 - val_acc: 0.9920\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0212 - acc: 0.9932 - val_loss: 0.0249 - val_acc: 0.9919\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0251 - val_acc: 0.9914\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0239 - val_acc: 0.9922\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0169 - acc: 0.9948 - val_loss: 0.0237 - val_acc: 0.9933\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.0256 - val_acc: 0.9925\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0253 - val_acc: 0.9921\n"
     ]
    }
   ],
   "source": [
    "newmodel.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "hist=newmodel.fit(X_train, Y_train, batch_size=128*4, epochs=20, verbose=1,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('MNIST_with_EMNIST_features.json', 'w') as f:\n",
    "    json.dump(hist.history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,290\n",
      "Non-trainable params: 1,198,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodel.layers[-1].trainable=True\n",
    "newmodel.layers[-3].trainable=False\n",
    "newmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 2.0154 - acc: 0.3141 - val_loss: 1.5295 - val_acc: 0.7560\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 1.5050 - acc: 0.5569 - val_loss: 1.1457 - val_acc: 0.8407\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 1.2768 - acc: 0.6256 - val_loss: 0.9362 - val_acc: 0.8614\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 1.1552 - acc: 0.6549 - val_loss: 0.8080 - val_acc: 0.8700\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 1.0819 - acc: 0.6710 - val_loss: 0.7233 - val_acc: 0.8768\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 1.0395 - acc: 0.6745 - val_loss: 0.6645 - val_acc: 0.8824\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 1.0115 - acc: 0.6790 - val_loss: 0.6234 - val_acc: 0.8859\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.9956 - acc: 0.6798 - val_loss: 0.5923 - val_acc: 0.8894\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.9744 - acc: 0.6858 - val_loss: 0.5686 - val_acc: 0.8916\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.9640 - acc: 0.6884 - val_loss: 0.5514 - val_acc: 0.8917\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.9530 - acc: 0.6898 - val_loss: 0.5366 - val_acc: 0.8944\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.9549 - acc: 0.6896 - val_loss: 0.5247 - val_acc: 0.8963\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.9500 - acc: 0.6899 - val_loss: 0.5161 - val_acc: 0.8960\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.9449 - acc: 0.6924 - val_loss: 0.5087 - val_acc: 0.8974\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.9387 - acc: 0.6950 - val_loss: 0.5022 - val_acc: 0.8985\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.9416 - acc: 0.6924 - val_loss: 0.4961 - val_acc: 0.8992\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.9350 - acc: 0.6917 - val_loss: 0.4927 - val_acc: 0.8983\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.9330 - acc: 0.6944 - val_loss: 0.4882 - val_acc: 0.8984\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.9334 - acc: 0.6939 - val_loss: 0.4840 - val_acc: 0.9003\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.9312 - acc: 0.6952 - val_loss: 0.4798 - val_acc: 0.9002\n"
     ]
    }
   ],
   "source": [
    "newmodel.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "hist=newmodel.fit(X_train, Y_train, batch_size=128*4, epochs=20, verbose=1,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MNIST_with_EMNIST_features_1.json', 'w') as f:\n",
    "    json.dump(hist.history, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
